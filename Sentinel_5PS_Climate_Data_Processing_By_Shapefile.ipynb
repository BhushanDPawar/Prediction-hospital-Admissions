{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ed78f2",
   "metadata": {},
   "source": [
    "# Sentinel-5P Dataset: Downloading and Processing for Malta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8923fa1",
   "metadata": {},
   "source": [
    "Description are given here: https://meeo-s5p.s3.amazonaws.com/index.html/kD2NDFdjCNyAQ2W89uMHSKP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7448276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't have wget installed, just uncomment the following line and run it\n",
    "#! pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3afb93de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Bhushan_SP5_ERA5_Processing_Script\n"
     ]
    }
   ],
   "source": [
    "# Getting the current working dirctory\n",
    "import os, sys # will be used to create and modify file name and save it\n",
    "pwd = os.getcwd()\n",
    "print(pwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361807ee",
   "metadata": {},
   "source": [
    "# Downloading Sulphur Dioxide (SO2)\n",
    "https://meeo-s5p.s3.amazonaws.com/index.html/kD2NDFdjCNyAQ2W89uMHSKP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99e894b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading.....S5P_OFFL_L2__SO2____20210101T233006_20210102T011136_16693_01_020104_20210104T010507.nc\n",
      "100% [......................................................................] 933737899 / 933737899S5P_OFFL_L2__SO2____20210101T233006_20210102T011136_16693_01_020104_20210104T010507.nc Downloaded Successfully!\n",
      "\n",
      "Downloading.....S5P_OFFL_L2__SO2____20210228T220550_20210228T234721_17515_01_020104_20210303T005922.nc\n",
      "100% [......................................................................] 971637177 / 971637177S5P_OFFL_L2__SO2____20210228T220550_20210228T234721_17515_01_020104_20210303T005922.nc Downloaded Successfully!\n",
      "No Data Available for the date 2021-01-02\n",
      "No Data Available for the date 2021-01-03\n",
      "No Data Available for the date 2021-01-04\n",
      "No Data Available for the date 2021-01-05\n",
      "No Data Available for the date 2021-01-06\n",
      "No Data Available for the date 2021-01-07\n",
      "No Data Available for the date 2021-01-08\n",
      "No Data Available for the date 2021-01-09\n",
      "No Data Available for the date 2021-01-10\n",
      "No Data Available for the date 2021-01-11\n",
      "No Data Available for the date 2021-01-12\n",
      "No Data Available for the date 2021-01-13\n",
      "No Data Available for the date 2021-01-14\n",
      "No Data Available for the date 2021-01-15\n",
      "No Data Available for the date 2021-01-16\n",
      "No Data Available for the date 2021-01-17\n",
      "No Data Available for the date 2021-01-18\n",
      "No Data Available for the date 2021-01-19\n",
      "No Data Available for the date 2021-01-20\n",
      "No Data Available for the date 2021-01-21\n",
      "No Data Available for the date 2021-01-22\n",
      "No Data Available for the date 2021-01-23\n",
      "No Data Available for the date 2021-01-24\n",
      "No Data Available for the date 2021-01-25\n",
      "No Data Available for the date 2021-01-26\n",
      "No Data Available for the date 2021-01-27\n",
      "No Data Available for the date 2021-01-28\n",
      "No Data Available for the date 2021-01-29\n",
      "No Data Available for the date 2021-01-30\n",
      "No Data Available for the date 2021-01-31\n",
      "No Data Available for the date 2021-02-01\n",
      "No Data Available for the date 2021-02-02\n",
      "No Data Available for the date 2021-02-03\n",
      "No Data Available for the date 2021-02-04\n",
      "No Data Available for the date 2021-02-05\n",
      "No Data Available for the date 2021-02-06\n",
      "No Data Available for the date 2021-02-07\n",
      "No Data Available for the date 2021-02-08\n",
      "No Data Available for the date 2021-02-09\n",
      "No Data Available for the date 2021-02-10\n",
      "No Data Available for the date 2021-02-11\n",
      "No Data Available for the date 2021-02-12\n",
      "No Data Available for the date 2021-02-13\n",
      "No Data Available for the date 2021-02-14\n",
      "No Data Available for the date 2021-02-15\n",
      "No Data Available for the date 2021-02-16\n",
      "No Data Available for the date 2021-02-17\n",
      "No Data Available for the date 2021-02-18\n",
      "No Data Available for the date 2021-02-19\n",
      "No Data Available for the date 2021-02-20\n",
      "No Data Available for the date 2021-02-21\n",
      "\n",
      "Downloading.....S5P_OFFL_L2__SO2____20210222T235922_20210223T014052_17431_01_020104_20210225T022809.nc\n",
      "100% [......................................................................] 972249467 / 972249467S5P_OFFL_L2__SO2____20210222T235922_20210223T014052_17431_01_020104_20210225T022809.nc Downloaded Successfully!\n",
      "\n",
      "Downloading.....S5P_OFFL_L2__SO2____20210222T171321_20210222T185451_17427_01_020104_20210224T201051.nc\n",
      "100% [......................................................................] 981237166 / 981237166S5P_OFFL_L2__SO2____20210222T171321_20210222T185451_17427_01_020104_20210224T201051.nc Downloaded Successfully!\n",
      "\n",
      "Downloading.....S5P_OFFL_L2__SO2____20210222T153150_20210222T171321_17426_01_020104_20210224T180523.nc\n",
      "100% [......................................................................] 977650412 / 977650412S5P_OFFL_L2__SO2____20210222T153150_20210222T171321_17426_01_020104_20210224T180523.nc Downloaded Successfully!\n",
      "\n",
      "Downloading.....S5P_OFFL_L2__SO2____20210222T084549_20210222T102719_17422_01_020104_20210224T105847.nc\n",
      "100% [......................................................................] 968747717 / 968747717S5P_OFFL_L2__SO2____20210222T084549_20210222T102719_17422_01_020104_20210224T105847.nc Downloaded Successfully!\n",
      "\n",
      "Downloading.....S5P_OFFL_L2__SO2____20210222T034118_20210222T052248_17419_01_020104_20210224T051923.nc\n",
      "100% [......................................................................] 940525129 / 940525129S5P_OFFL_L2__SO2____20210222T034118_20210222T052248_17419_01_020104_20210224T051923.nc Downloaded Successfully!\n",
      "\n",
      "Downloading.....S5P_OFFL_L2__SO2____20210222T185451_20210222T203621_17428_01_020104_20210224T212426.nc\n",
      " 83% [..........................................................            ] 783196160 / 936634475"
     ]
    }
   ],
   "source": [
    "# First changing the working directory to current as all the paths are set relative to current working directory\n",
    "\"\"\"This script automatically generates the url and downlaod the CHIRPS Rainfall dataset\"\"\"\n",
    "import wget\n",
    "import requests\n",
    "import json\n",
    "import os, sys\n",
    "from calendar import monthrange\n",
    "#os.chdir(pwd)\n",
    "#Specify the start and end year of dataset\n",
    "start_year =  2021 # yyyy\n",
    "end_year = 2021\n",
    "# Specify the working directory\n",
    "path = \"./\"\n",
    "download_dir = os.path.join(path,\"S5P_SO2\")\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "# sample link: https://meeo-s5p.s3.amazonaws.com/OFFL/L2__AER_AI/2021/04/01/S5P_OFFL_L2__AER_AI_20210401T015128_20210401T033259_17957_01_010400_20210402T153421.nc\n",
    "base_site = \"https://meeo-s5p.s3.amazonaws.com/OFFL/\"\n",
    "#json_file = \"https://meeo-s5p.s3.amazonaws.com/OFFL/L2__SO2___/2021/04/01/catalog.json\"\n",
    "################################################\n",
    "for year in range(start_year, end_year+1,1):\n",
    "    for month in range(1,13):\n",
    "        month = str(month).zfill(2)\n",
    "        #print(month)\n",
    "        for day in range(1,(monthrange(year, int(month))[1])+1):\n",
    "            day = \"{:02d}\".format(day)\n",
    "            #print(day)\n",
    "            json_url = \"{}{}/{}/{}/{}/{}\".format(base_site,\"L2__SO2___\",year,month,day,\"catalog.json\")\n",
    "            file_ext  = \".nc\"\n",
    "            #print(json_file)\n",
    "            #url = \"https://meeo-s5p.s3.amazonaws.com/OFFL/L2__AER_AI/2021/04/01/catalog.json\"\n",
    "            response = requests.get(json_url)\n",
    "            if response.status_code == 200:\n",
    "                data = json.loads(response.text)\n",
    "                #print(dir(data))\n",
    "                #print(list(data[\"links\"]))\n",
    "                urls = data[\"links\"]\n",
    "                for url in range(3,len(urls)):\n",
    "                    #print(urls[url]['href'])\n",
    "                    json_url = urls[url]['href']\n",
    "                    download_url, ext = os.path.splitext(json_url)\n",
    "                    file_name = download_url.split('/')[-1]\n",
    "                    file_name = \"{}{}\".format(file_name,file_ext)\n",
    "                    download_url = \"{}{}\".format(download_url,file_ext)\n",
    "                    #print(download_url)\n",
    "                    print(\"{}{}\".format(\"\\nDownloading.....\",file_name))\n",
    "                    wget.download(download_url,download_dir)\n",
    "                    print(\"{}{}\".format(file_name,\" Downloaded Successfully!\"))\n",
    "                \n",
    "            else:\n",
    "                print(\"No Data Available for the date {}-{}-{}\".format(year,month,day))\n",
    "print(\"\\nAll Data Have Been Downloaded Successfully!\\n\\n\\n\")           \n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdfce37",
   "metadata": {},
   "source": [
    "# Downloading Carbon Monoxide (CO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "005054ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading.....S5P_OFFL_L2__CO_____20210101T045336_20210101T063506_16682_01_010400_20210102T184045.nc\n",
      "  1% [.                                                                     ]   3129344 / 178385339"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9108\\2644408685.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m                     \u001b[1;31m#print(download_url)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nDownloading.....\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m                     \u001b[0mwget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdownload_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdownload_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" Downloaded Successfully!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wget.py\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(url, out, bar)\u001b[0m\n\u001b[0;32m    524\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[0mbinurl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mtmpfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mulib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinurl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmpfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_filename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moutdir\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m                 \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    461\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[1;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[1;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m             \u001b[1;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1242\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1243\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# First changing the working directory to current as all the paths are set relative to current working directory\n",
    "\"\"\"This script automatically generates the url and downlaod the CHIRPS Rainfall dataset\"\"\"\n",
    "import wget\n",
    "import requests\n",
    "import json\n",
    "import os, sys\n",
    "from calendar import monthrange\n",
    "#os.chdir(pwd)\n",
    "#Specify the start and end year of dataset\n",
    "start_year =  2021 # yyyy\n",
    "end_year = 2021\n",
    "# Specify the working directory\n",
    "path = \"./\"\n",
    "download_dir = os.path.join(path,\"S5P_CO\")\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "# sample link: https://meeo-s5p.s3.amazonaws.com/OFFL/L2__AER_AI/2021/04/01/S5P_OFFL_L2__AER_AI_20210401T015128_20210401T033259_17957_01_010400_20210402T153421.nc\n",
    "base_site = \"https://meeo-s5p.s3.amazonaws.com/OFFL/\"\n",
    "#json_file = \"https://meeo-s5p.s3.amazonaws.com/OFFL/L2__CO____/2021/04/01/catalog.json\"\n",
    "################################################\n",
    "for year in range(start_year, end_year+1,1):\n",
    "    for month in range(1,13):\n",
    "        month = str(month).zfill(2)\n",
    "        #print(month)\n",
    "        for day in range(1,(monthrange(year, int(month))[1])+1):\n",
    "            day = \"{:02d}\".format(day)\n",
    "            #print(day)\n",
    "            json_url = \"{}{}/{}/{}/{}/{}\".format(base_site,\"L2__CO____\",year,month,day,\"catalog.json\")\n",
    "            file_ext  = \".nc\"\n",
    "            #print(json_file)\n",
    "            #url = \"https://meeo-s5p.s3.amazonaws.com/OFFL/L2__AER_AI/2021/04/01/catalog.json\"\n",
    "            response = requests.get(json_url)\n",
    "            if response.status_code == 200:\n",
    "                data = json.loads(response.text)\n",
    "                #print(dir(data))\n",
    "                #print(list(data[\"links\"]))\n",
    "                urls = data[\"links\"]\n",
    "                for url in range(3,len(urls)):\n",
    "                    #print(urls[url]['href'])\n",
    "                    json_url = urls[url]['href']\n",
    "                    download_url, ext = os.path.splitext(json_url)\n",
    "                    file_name = download_url.split('/')[-1]\n",
    "                    file_name = \"{}{}\".format(file_name,file_ext)\n",
    "                    download_url = \"{}{}\".format(download_url,file_ext)\n",
    "                    #print(download_url)\n",
    "                    print(\"{}{}\".format(\"\\nDownloading.....\",file_name))\n",
    "                    wget.download(download_url,download_dir)\n",
    "                    print(\"{}{}\".format(file_name,\" Downloaded Successfully!\"))\n",
    "                \n",
    "            else:\n",
    "                print(\"No Data Available for the date {}-{}-{}\".format(year,month,day))\n",
    "print(\"\\nAll Data Have Been Downloaded Successfully!\\n\\n\\n\")           \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dddcc75",
   "metadata": {},
   "source": [
    "# Downloading Cloud fraction, top pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a845a324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Data Available for the date 2021-01-01\n",
      "No Data Available for the date 2021-01-02\n",
      "No Data Available for the date 2021-01-03\n",
      "No Data Available for the date 2021-01-04\n",
      "No Data Available for the date 2021-01-05\n",
      "No Data Available for the date 2021-01-06\n",
      "No Data Available for the date 2021-01-07\n",
      "No Data Available for the date 2021-01-08\n",
      "No Data Available for the date 2021-01-09\n",
      "No Data Available for the date 2021-01-10\n",
      "No Data Available for the date 2021-01-11\n",
      "No Data Available for the date 2021-01-12\n",
      "No Data Available for the date 2021-01-13\n",
      "No Data Available for the date 2021-01-14\n",
      "No Data Available for the date 2021-01-15\n",
      "No Data Available for the date 2021-01-16\n",
      "No Data Available for the date 2021-01-17\n",
      "No Data Available for the date 2021-01-18\n",
      "No Data Available for the date 2021-01-19\n",
      "No Data Available for the date 2021-01-20\n",
      "No Data Available for the date 2021-01-21\n",
      "No Data Available for the date 2021-01-22\n",
      "No Data Available for the date 2021-01-23\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9108\\3318764628.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;31m#print(json_file)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;31m#url = \"https://meeo-s5p.s3.amazonaws.com/OFFL/L2__AER_AI/2021/04/01/catalog.json\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \"\"\"\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"get\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    585\u001b[0m         }\n\u001b[0;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    490\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m                     \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[1;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m             \u001b[1;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1040\u001b[0m         \u001b[1;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sock\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_default_certs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m         self.sock = ssl_wrap_socket(\n\u001b[0m\u001b[0;32m    415\u001b[0m             \u001b[0msock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m             \u001b[0mkeyfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msend_sni\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m         ssl_sock = _ssl_wrap_socket_impl(\n\u001b[0m\u001b[0;32m    450\u001b[0m             \u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtls_in_tls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\ssl_.py\u001b[0m in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;31m# SSLSocket class handles server_hostname encoding before it calls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;31m# ctx._wrap_socket()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m         return self.sslsocket_class._create(\n\u001b[0m\u001b[0;32m    502\u001b[0m             \u001b[0msock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m             \u001b[0mserver_side\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_side\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36m_create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1039\u001b[0m                         \u001b[1;31m# non-blocking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1308\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1310\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1311\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# First changing the working directory to current as all the paths are set relative to current working directory\n",
    "\"\"\"This script automatically generates the url and downlaod the CHIRPS Rainfall dataset\"\"\"\n",
    "import wget\n",
    "import requests\n",
    "import json\n",
    "import os, sys\n",
    "from calendar import monthrange\n",
    "#os.chdir(pwd)\n",
    "#Specify the start and end year of dataset\n",
    "start_year =  2021 # yyyy\n",
    "end_year = 2021\n",
    "# Specify the working directory\n",
    "path = \"./\"\n",
    "download_dir = os.path.join(path,\"S5P_CLOUD\")\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "# sample link: https://meeo-s5p.s3.amazonaws.com/OFFL/L2__AER_AI/2021/04/01/S5P_OFFL_L2__AER_AI_20210401T015128_20210401T033259_17957_01_010400_20210402T153421.nc\n",
    "base_site = \"https://meeo-s5p.s3.amazonaws.com/OFFL/\"\n",
    "#json_file = \"https://meeo-s5p.s3.amazonaws.com/OFFL/L2__CLOUD_/2021/04/01/catalog.json\"\n",
    "################################################\n",
    "for year in range(start_year, end_year+1,1):\n",
    "    for month in range(1,13):\n",
    "        month = str(month).zfill(2)\n",
    "        #print(month)\n",
    "        for day in range(1,(monthrange(year, int(month))[1])+1):\n",
    "            day = \"{:02d}\".format(day)\n",
    "            #print(day)\n",
    "            json_url = \"{}{}/{}/{}/{}/{}\".format(base_site,\"L2__CLOUD_\",year,month,day,\"catalog.json\")\n",
    "            file_ext  = \".nc\"\n",
    "            #print(json_file)\n",
    "            #url = \"https://meeo-s5p.s3.amazonaws.com/OFFL/L2__AER_AI/2021/04/01/catalog.json\"\n",
    "            response = requests.get(json_url)\n",
    "            if response.status_code == 200:\n",
    "                data = json.loads(response.text)\n",
    "                #print(dir(data))\n",
    "                #print(list(data[\"links\"]))\n",
    "                urls = data[\"links\"]\n",
    "                for url in range(3,len(urls)):\n",
    "                    #print(urls[url]['href'])\n",
    "                    json_url = urls[url]['href']\n",
    "                    download_url, ext = os.path.splitext(json_url)\n",
    "                    file_name = download_url.split('/')[-1]\n",
    "                    file_name = \"{}{}\".format(file_name,file_ext)\n",
    "                    download_url = \"{}{}\".format(download_url,file_ext)\n",
    "                    #print(download_url)\n",
    "                    print(\"{}{}\".format(\"\\nDownloading.....\",file_name))\n",
    "                    wget.download(download_url,download_dir)\n",
    "                    print(\"{}{}\".format(file_name,\" Downloaded Successfully!\"))\n",
    "                \n",
    "            else:\n",
    "                print(\"No Data Available for the date {}-{}-{}\".format(year,month,day))\n",
    "print(\"\\nAll Data Have Been Downloaded Successfully!\\n\\n\\n\")           \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101ed91c",
   "metadata": {},
   "source": [
    "# Downloading UV Aerosol Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2ffdd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Data Available for the date 2021-01-01\n",
      "No Data Available for the date 2021-01-02\n",
      "No Data Available for the date 2021-01-03\n",
      "No Data Available for the date 2021-01-04\n",
      "No Data Available for the date 2021-01-05\n",
      "No Data Available for the date 2021-01-06\n",
      "No Data Available for the date 2021-01-07\n",
      "No Data Available for the date 2021-01-08\n",
      "No Data Available for the date 2021-01-09\n",
      "No Data Available for the date 2021-01-10\n",
      "No Data Available for the date 2021-01-11\n",
      "No Data Available for the date 2021-01-12\n",
      "No Data Available for the date 2021-01-13\n",
      "No Data Available for the date 2021-01-14\n",
      "No Data Available for the date 2021-01-15\n",
      "No Data Available for the date 2021-01-16\n",
      "No Data Available for the date 2021-01-17\n",
      "No Data Available for the date 2021-01-18\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9108\\587902463.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;31m#print(json_file)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;31m#url = \"https://meeo-s5p.s3.amazonaws.com/OFFL/L2__AER_AI/2021/04/01/catalog.json\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \"\"\"\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"get\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    585\u001b[0m         }\n\u001b[0;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    490\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m                     \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[1;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m             \u001b[1;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1040\u001b[0m         \u001b[1;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sock\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;31m# Add certificate verification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[0mtls_in_tls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             conn = connection.create_connection(\n\u001b[0m\u001b[0;32m    175\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# First changing the working directory to current as all the paths are set relative to current working directory\n",
    "\"\"\"This script automatically generates the url and downlaod the CHIRPS Rainfall dataset\"\"\"\n",
    "import wget\n",
    "import requests\n",
    "import json\n",
    "import os, sys\n",
    "from calendar import monthrange\n",
    "#os.chdir(pwd)\n",
    "#Specify the start and end year of dataset\n",
    "start_year =  2021 # yyyy\n",
    "end_year = 2021\n",
    "# Specify the working directory\n",
    "path = \"./\"\n",
    "download_dir = os.path.join(path,\"S5P_AER_AI\")\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "#Varialbes = ['L2__AER_AI',]\n",
    "# sample link: https://meeo-s5p.s3.amazonaws.com/OFFL/L2__AER_AI/2021/04/01/S5P_OFFL_L2__AER_AI_20210401T015128_20210401T033259_17957_01_010400_20210402T153421.nc\n",
    "base_site = \"https://meeo-s5p.s3.amazonaws.com/OFFL/\"\n",
    "json_file = \"https://meeo-s5p.s3.amazonaws.com/OFFL/L2__AER_AI/2021/04/01/catalog.json\"\n",
    "# Sample file name: S5P_OFFL_L2__AER_AI_20210401T015128_20210401T033259_17957_01_010400_20210402T153421.nc\n",
    "################################################\n",
    "for year in range(start_year, end_year+1,1):\n",
    "    for month in range(1,13):\n",
    "        month = str(month).zfill(2)\n",
    "        #print(month)\n",
    "        for day in range(1,(monthrange(year, int(month))[1])+1):\n",
    "            day = \"{:02d}\".format(day)\n",
    "            #print(day)\n",
    "            json_url = \"{}{}/{}/{}/{}/{}\".format(base_site,\"L2__AER_AI\",year,month,day,\"catalog.json\")\n",
    "            file_ext  = \".nc\"\n",
    "            #print(json_file)\n",
    "            #url = \"https://meeo-s5p.s3.amazonaws.com/OFFL/L2__AER_AI/2021/04/01/catalog.json\"\n",
    "            response = requests.get(json_url)\n",
    "            if response.status_code == 200:\n",
    "                data = json.loads(response.text)\n",
    "                #print(dir(data))\n",
    "                #print(list(data[\"links\"]))\n",
    "                urls = data[\"links\"]\n",
    "                for url in range(3,len(urls)):\n",
    "                    #print(urls[url]['href'])\n",
    "                    json_url = urls[url]['href']\n",
    "                    download_url, ext = os.path.splitext(json_url)\n",
    "                    file_name = download_url.split('/')[-1]\n",
    "                    file_name = \"{}{}\".format(file_name,file_ext)\n",
    "                    download_url = \"{}{}\".format(download_url,file_ext)\n",
    "                    #print(download_url)\n",
    "                    print(\"{}{}\".format(\"\\nDownloading.....\",file_name))\n",
    "                    wget.download(download_url,download_dir)\n",
    "                    print(\"{}{}\".format(file_name,\" Downloaded Successfully!\"))\n",
    "                \n",
    "            else:\n",
    "                print(\"No Data Available for the date {}-{}-{}\".format(year,month,day))\n",
    "print(\"\\nAll Data Have Been Downloaded Successfully!\\n\\n\\n\")           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc984673",
   "metadata": {},
   "source": [
    "# Downloading Climate Data From ECMWF (ERA5)\n",
    "https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c679e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 14:25:46,916 INFO Welcome to the CDS\n",
      "2023-03-07 14:25:46,927 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-03-07 14:25:47,155 INFO Request is queued\n",
      "2023-03-07 14:25:48,207 INFO Request is running\n",
      "2023-03-07 14:30:05,406 INFO Request is completed\n",
      "2023-03-07 14:30:05,406 INFO Downloading https://download-0020.copernicus-climate.eu/cache-compute-0020/cache/data3/adaptor.mars.internal-1678195748.335315-6009-11-d3ccc9c0-30a3-4cf5-870a-888703a8efff.nc to Wind_press_Temp.nc (1.3M)\n",
      "2023-03-07 14:30:06,055 INFO Download rate 2M/s                                                                        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(content_length=1375296,content_type=application/x-netcdf,location=https://download-0020.copernicus-climate.eu/cache-compute-0020/cache/data3/adaptor.mars.internal-1678195748.335315-6009-11-d3ccc9c0-30a3-4cf5-870a-888703a8efff.nc)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cdsapi\n",
    "\n",
    "c = cdsapi.Client()\n",
    "\n",
    "c.retrieve(\n",
    "    'reanalysis-era5-single-levels',\n",
    "    {\n",
    "        'product_type': 'reanalysis',\n",
    "        'variable': [\n",
    "            '10m_u_component_of_wind', '10m_v_component_of_wind', '2m_temperature',\n",
    "            'surface_pressure',\n",
    "        ],\n",
    "        'year': [\n",
    "            '2019', '2020', '2021','2022'\n",
    "        ],\n",
    "        'month': [\n",
    "            '01', '02', '03',\n",
    "            '04', '05', '06',\n",
    "            '07', '08', '09',\n",
    "            '10', '11', '12',\n",
    "        ],\n",
    "        'day': [\n",
    "            '01', '02', '03',\n",
    "            '04', '05', '06',\n",
    "            '07', '08', '09',\n",
    "            '10', '11', '12',\n",
    "            '13', '14', '15',\n",
    "            '16', '17', '18',\n",
    "            '19', '20', '21',\n",
    "            '22', '23', '24',\n",
    "            '25', '26', '27',\n",
    "            '28', '29', '30',\n",
    "            '31',\n",
    "        ],\n",
    "        'time': [\n",
    "            '12:00'\n",
    "        ],\n",
    "        'area': [\n",
    "            37, 14, 34,\n",
    "            16,\n",
    "        ],\n",
    "        'format': 'netcdf',\n",
    "    },\n",
    "    'Wind_press_Temp.nc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b777823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 14:30:06,145 INFO Welcome to the CDS\n",
      "2023-03-07 14:30:06,146 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-pressure-levels\n",
      "2023-03-07 14:30:06,189 INFO Request is queued\n",
      "2023-03-07 14:30:07,252 INFO Request is running\n",
      "2023-03-07 14:30:55,919 INFO Request is completed\n",
      "2023-03-07 14:30:55,922 INFO Downloading https://download-0005-clone.copernicus-climate.eu/cache-compute-0005/cache/data7/adaptor.mars_constrained.internal-1678195833.30538-13297-2-d19816f0-8d45-4fad-9134-69b7a9def3fe.nc to RH.nc (722.8M)\n",
      "2023-03-07 14:34:29,653 INFO Download rate 3.4M/s                                                                      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(content_length=757926448,content_type=application/x-netcdf,location=https://download-0005-clone.copernicus-climate.eu/cache-compute-0005/cache/data7/adaptor.mars_constrained.internal-1678195833.30538-13297-2-d19816f0-8d45-4fad-9134-69b7a9def3fe.nc)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cdsapi\n",
    "\n",
    "c = cdsapi.Client()\n",
    "\n",
    "c.retrieve(\n",
    "    'reanalysis-era5-pressure-levels',\n",
    "    {\n",
    "        'product_type': 'reanalysis',\n",
    "        'format': 'netcdf',\n",
    "        'variable': 'relative_humidity',\n",
    "        'pressure_level': '100',\n",
    "        'year': '2021',\n",
    "        'month': [\n",
    "            '01', '02', '03',\n",
    "            '04', '05', '06',\n",
    "            '07', '08', '09',\n",
    "            '10', '11', '12',\n",
    "        ],\n",
    "        'day': [\n",
    "            '01', '02', '03',\n",
    "            '04', '05', '06',\n",
    "            '07', '08', '09',\n",
    "            '10', '11', '12',\n",
    "            '13', '14', '15',\n",
    "            '16', '17', '18',\n",
    "            '19', '20', '21',\n",
    "            '22', '23', '24',\n",
    "            '25', '26', '27',\n",
    "            '28', '29', '30',\n",
    "            '31',\n",
    "        ],\n",
    "        'time': [\n",
    "            '12:00'\n",
    "        ],\n",
    "    },\n",
    "    'RH.nc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc4bcefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install netCDF4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc248d0",
   "metadata": {},
   "source": [
    "## Extraction of Required Variables From the NetCDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b145b808",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'netCDF4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19804\\236906138.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# First importing the necessary modules to read and process the netcdf data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m \u001b[1;31m# will be used to create and modify file name and save it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnetCDF4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m \u001b[1;31m# Dataset method in netCDF4 library will be used to read .nc, .nc4 files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m \u001b[1;31m# pandas module will be used to read and modify dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtimedelta\u001b[0m \u001b[1;31m# will be used to manipulate date and time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'netCDF4'"
     ]
    }
   ],
   "source": [
    "# First importing the necessary modules to read and process the netcdf data\n",
    "import os, sys # will be used to create and modify file name and save it\n",
    "from netCDF4 import Dataset # Dataset method in netCDF4 library will be used to read .nc, .nc4 files\n",
    "import pandas as pd # pandas module will be used to read and modify dataframe\n",
    "from datetime import datetime,timedelta # will be used to manipulate date and time\n",
    "import matplotlib.pyplot as plt # will be used to plot the data\n",
    "import numpy as np\n",
    "import datetime # will be used to manipulate the datetime\n",
    "import warnings # Will be used to ignore the unnecessary warning so that the code look good esthetically\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad1da0d",
   "metadata": {},
   "source": [
    "## Understanding the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a091f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now reading the netCDF file from the directory where it is located, \"r\" stands for reading mode\n",
    "# Reading only one arbitrary file to observe the variables\n",
    "data = Dataset(\"D:\\\\Bhushan_SP5_ERA5_Processing_Script\\\\ERA5_RH_Malta1.nc\", 'r')\n",
    "# After reading the data as an object stored as 'data' here, printing the variables it has as follows:\n",
    "print(\"Here are all the variables of your data\")\n",
    "print(data.variables.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ab9ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19966ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rh = data.variables['r'] \n",
    "rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7707068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the unit of the precipitaiton mentioned in the file\n",
    "unitrh = data.variables['r'].units \n",
    "unitrh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f2f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading all the lat values and showing. Lats are ranging from -90 to +90\n",
    "lats = data.variables['latitude']\n",
    "lats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d3e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = data.variables['latitude'][:]\n",
    "lats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb8b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading all the lon values and showing. Lons are ranging from -180 to +180\n",
    "lons = data.variables['longitude'][:] # total precipitation\n",
    "lons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37fe11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading all the time steps and showing. Lons are ranging from -180 to +180\n",
    "times = data.variables['time'] # total precipitation\n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2498c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading all the time steps and showing. Lons are ranging from -180 to +180\n",
    "times = data.variables['time'][:10] # total precipitation\n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92960a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "unitt = data.variables['time'].units \n",
    "unitt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5071de84",
   "metadata": {},
   "source": [
    "#### Notice that the unit of time is in hours from the reference date time!\n",
    "From the time values and units. it's confirm that the data are stored at hourly intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b703e2db",
   "metadata": {},
   "source": [
    "## Clipping The NetCDF Files by Shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f83ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importig required modules\n",
    "import xarray as xr \n",
    "import numpy as np\n",
    "import regionmask\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings; warnings.filterwarnings(action='ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908dd281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the shapefile and extracting the attributes \n",
    "shapefile = \"D:\\\\Bhushan_SP5_ERA5_Processing_Script\\\\MLT_adm\\\\MLT_adm0.shp\"\n",
    "countries = gpd.read_file(shapefile,crs=\"epsg:4326\")\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45662851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the study area\n",
    "fig, ax = plt.subplots(figsize=(16,10))\n",
    "countries.plot(ax=ax,column = 'ISO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744177e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the lat lons\n",
    "print(countries.loc[0,'geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebca7b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the indeces \n",
    "my_list = list(countries['NAME_ISO'])\n",
    "my_list_unique = set(list(countries['NAME_ISO']))\n",
    "indexes = [my_list.index(x) for x in my_list_unique]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63308c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the bounday mask as polygon\n",
    "countries_mask_poly = regionmask.Regions_cls(name = 'NAME_ISO', numbers = indexes, names = countries.NAME_ISO[indexes], abbrevs = countries.NAME_ISO[indexes], outlines = list(countries.geometry.values[i] for i in range(0,countries.shape[0])))\n",
    "countries_mask_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e7cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the Name of the study area\n",
    "print(\"{}\".format(countries_mask_poly.names[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc86a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now reading the netcdf files using xarray\n",
    "# The following command is for data with both single and multiple varialbes\n",
    "ds = xr.open_dataset(\"D:\\\\Bhushan_SP5_ERA5_Processing_Script\\\\ERA5_RH_Malta1.nc\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3415ca3c",
   "metadata": {},
   "source": [
    "### We can see that the NetCDF file contains only one variable which is Relative Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348ee987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot relative Humidity for a time period\n",
    "plt.figure(figsize=(16,10))\n",
    "ax = plt.axes()\n",
    "ds.r.isel(time = 2500).plot(ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99211b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the resolution of the data is coarse (i.e., 0.25 deg X 0.25 deg) and the size of the study area is very small,\n",
    "# We need to increase the resolution of the data in the NetCDF file.\n",
    "# Create new lat and lon\n",
    "dx_new = 0.05\n",
    "newlon = np.arange(14, 16, dx_new)\n",
    "newlat = np.arange(34, 37+dx_new, dx_new)\n",
    "\n",
    "# Interpolating the data onto the new grids\n",
    "data_set_interp = ds.interp(latitude=newlat, longitude=newlon)\n",
    "\n",
    "# Check output\n",
    "print(data_set_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c333c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the interpolated data again to see the changes in the resolution\n",
    "plt.figure(figsize=(16,10))\n",
    "ax = plt.axes()\n",
    "data_set_interp.r.isel(time = 2500).plot(ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1ced4d",
   "metadata": {},
   "source": [
    "### We can notice that the resolution of the data has incresed significantly after the interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867978f2",
   "metadata": {},
   "source": [
    "### Test code for making interpolation\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Create sample data\n",
    "dx  = 0.25\n",
    "lon = np.arange(0, 360, dx)\n",
    "lat = np.arange(-90, 90+dx, dx)\n",
    "data = 10 * np.random.rand(len(lat), len(lon))\n",
    "data_set = xr.Dataset({\"temp\": ([\"lat\", \"lon\"], data)},\n",
    "                 coords={\"lon\": lon,\"lat\": lat})\n",
    "\n",
    "### Just checking the datasets are not empty\n",
    "print(data_set)\n",
    "\n",
    "### Create new lat and lon\n",
    "dx_new = 0.125\n",
    "newlon = np.arange(0, 360, dx_new)\n",
    "newlat = np.arange(-90, 90+dx_new, dx_new)\n",
    "\n",
    "### Interpolate\n",
    "data_set_interp = data_set.interp(lat=newlat, lon=newlon)\n",
    "\n",
    "### Check output\n",
    "print(data_set_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a502d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a mask based on the shapefile that will be used to clip the data from the .nc file\n",
    "print(\"Masking takes a while, please wait............\")\n",
    "mask = countries_mask_poly.mask(data_set_interp.isel(time = 0),lat_name='latitude', lon_name='longitude')\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8732e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The masked can be saved for future use as it always takes long time to generate. It's better to save\n",
    "mask.to_netcdf('D:\\\\Bhushan_SP5_ERA5_Processing_Script\\\\mask_by_Malta.nc') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d858ad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the mask from the disk as I saved it previously\n",
    "mask = xr.open_dataarray('D:\\\\Bhushan_SP5_ERA5_Processing_Script\\\\mask_by_Malta.nc')\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce6ba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking the data based on the masked created using shapefile\n",
    "masked_shape = data_set_interp.where(mask == 0)\n",
    "masked_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2289a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the masked data for a time step only to check if the masking has been successfull\n",
    "plt.figure(figsize=(12,8))\n",
    "ax = plt.axes()\n",
    "masked_shape.r.isel(time = 5000).plot(ax = ax)\n",
    "countries.plot(ax = ax, alpha = 0.8, facecolor = 'none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ca1670",
   "metadata": {},
   "source": [
    "### We notice that the masking is successfull using the shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87a8eff",
   "metadata": {},
   "source": [
    "Extracting time-series for one specific location\n",
    "In this example, we want to extract time-series for a location with the following latitude and longitude:\n",
    "longitude = 14.4; latitude = 35.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5303e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting time-series of relative humidity for the above-mentioned location\n",
    "latitude = 35.9\n",
    "longitude = 14.4\n",
    "data  = masked_shape.r.sel(longitude=longitude, latitude=latitude, method='nearest') \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca1f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe from xarray and plotting\n",
    "df = data.to_dataframe()\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "df['r'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baf61ba",
   "metadata": {},
   "source": [
    "### The data is for 5 years starting from 01 Jan 2017 to 31 Dec 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eff1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets plot montlhy distribution of relative humidity for Malta:\n",
    "df['Month'] = df.index.strftime(\"%b\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7d7b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the box-plot of monthly distribution\n",
    "import seaborn as sns\n",
    "ax = plt.axes()\n",
    "sns.boxplot(x=\"Month\", y=\"r\", data=df, palette=\"Set1\")  \n",
    "figure = ax.get_figure()    \n",
    "figure.set_size_inches(12, 8) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87a244e",
   "metadata": {},
   "source": [
    "## Everything Looks alright, Now saving the masked data as .nc format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4011be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data to the same location as input\n",
    "encoding = {\"r\": {'zlib': True,\"complevel\": 4}}\n",
    "#format='NETCDF4', engine='netcdf4',encoding={'Tair': {'zlib': True,'dtype': 'float32', '_FillValue': -9999}}\n",
    "masked_shape.to_netcdf('D:\\\\Bhushan_SP5_ERA5_Processing_Script\\\\ERA5_RH_Malta_Clipped.nc',mode='w',format='NETCDF4', engine='netcdf4',encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772a2bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can read the saved nc file and extract a time series as well\n",
    "# The following command is for data with single varialbe\n",
    "data = xr.open_dataarray('D:\\\\Bhushan_SP5_ERA5_Processing_Script\\\\ERA5_RH_Malta_Clipped.nc')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b53c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the masked data after reading from the clipped .nc file\n",
    "plt.figure(figsize=(16,10))\n",
    "ax = plt.axes()\n",
    "# Just plotting one variable\n",
    "data.isel(time = 2500).plot(ax = ax)\n",
    "countries.plot(ax = ax, alpha = 0.8, facecolor = 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aef8141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are extracting the time series for a single point and plotting the time series\n",
    "# the latitude and longitude of the point of interest are 35.90 and 14.4 degrees, respectively.\n",
    "single_point = data.sel(latitude=35.90, longitude=14.4, method ='nearest')\n",
    "single_point.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79622d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now clipping the climate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10a259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now reading the netcdf files using xarray\n",
    "# The following command is for data with both single and multiple varialbes\n",
    "ds = xr.open_dataset(\"D:\\\\Bhushan_SP5_ERA5_Processing_Script\\\\ERA5_Climate_Malta.nc\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58e7d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the resolution of the data is coarse (i.e., 0.25 deg X 0.25 deg) and the size of the study area is very small,\n",
    "# We need to increase the resolution of the data in the NetCDF file.\n",
    "# Create new lat and lon\n",
    "dx_new = 0.05\n",
    "newlon = np.arange(14, 16, dx_new)\n",
    "newlat = np.arange(34, 37+dx_new, dx_new)\n",
    "\n",
    "# Interpolating the data onto the new grids\n",
    "data_set_interp = ds.interp(latitude=newlat, longitude=newlon)\n",
    "\n",
    "# Check output\n",
    "print(data_set_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885b4be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking the data based on the masked created using shapefile\n",
    "masked_shape = data_set_interp.where(mask == 0)\n",
    "masked_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9ceb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data to the same location as input\n",
    "encoding = {\"t2m\": {'zlib': True,\"complevel\": 4}}\n",
    "#format='NETCDF4', engine='netcdf4',encoding={'Tair': {'zlib': True,'dtype': 'float32', '_FillValue': -9999}}\n",
    "masked_shape.to_netcdf('D:\\\\Bhushan_SP5_ERA5_Processing_Script\\\\ERA5_Climate_Malta_Clipped.nc',mode='w',format='NETCDF4', engine='netcdf4',encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e955ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can read the saved nc file and extract a time series as well\n",
    "# The following command is for data with single varialbe\n",
    "data = xr.open_dataset('D:\\\\Bhushan_SP5_ERA5_Processing_Script\\\\ERA5_Climate_Malta_Clipped.nc')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2da4cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting time-series of relative humidity for the above-mentioned location\n",
    "latitude = 35.9\n",
    "longitude = 14.4\n",
    "data  = masked_shape.t2m.sel(longitude=longitude, latitude=latitude, method='nearest') \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9517c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe from xarray and plotting\n",
    "df = data.to_dataframe()\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "df['t2m'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02efe1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets plot montlhy distribution of relative humidity for Malta:\n",
    "df['Month'] = df.index.strftime(\"%b\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d772795",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's see the box-plot of monthly distribution\n",
    "import seaborn as sns\n",
    "ax = plt.axes()\n",
    "sns.boxplot(x=\"Month\", y=\"t2m\", data=df, palette=\"Set1\")  \n",
    "figure = ax.get_figure()    \n",
    "figure.set_size_inches(12, 8) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57820cf5",
   "metadata": {},
   "source": [
    "# Sentinel-5P Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e643a5e3",
   "metadata": {},
   "source": [
    "## 1. Loading necessary Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4462ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipyleaflet\n",
    "#!pip install termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f04931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, DrawControl\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "from termcolor import colored\n",
    "import cartopy.feature as cf\n",
    "import cartopy.crs as ccrs\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import ipyleaflet\n",
    "import cartopy\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b603f4",
   "metadata": {},
   "source": [
    "## 2. Load and explore Sentinel-5P product (SO2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b22796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "input_dir = \"C:/Users/mxr8032/Downloads/Bhushan_Pawar/S5P_SO2/\"\n",
    "s5p_files = sorted([f for f in glob.glob(input_dir + \"*SO2*.nc\", recursive = True)])\n",
    "#print(s5p_files)\n",
    "\n",
    "for i, file in enumerate(s5p_files):\n",
    "    s5p_split = file.split(\"/\")\n",
    "    s5p_split_file = s5p_split[-1].split(\"_\")\n",
    "    print(\"#{}: {} \\n\".format(i,s5p_split[-1]),\n",
    "         colored(\"Mission:\", \"blue\"),\"{}\".format(s5p_split_file[0]),\n",
    "         colored(\"Stream | Level:\", \"blue\"), \"{} | {}\".format(s5p_split_file[1], s5p_split_file[2]),\n",
    "         colored(\"Product identifier:\", \"blue\"), \"{}\".format(s5p_split_file[4]),\n",
    "         colored(\"Start | End:\", \"blue\"), \"{} | {}\".format(s5p_split_file[8],s5p_split_file[9]),\n",
    "         colored(\"Orbit:\", \"blue\"), \"{}\".format(s5p_split_file[10]),\n",
    "         colored(\"Collect.:\", \"blue\"), \"{}\".format(s5p_split_file[11]),\n",
    "         colored(\"Processor:\", \"blue\"), \"{}\".format(s5p_split_file[12]),\n",
    "         colored(\"Process time:\", \"blue\"), \"{}\".format(s5p_split_file[13]), \"\\n\"\n",
    "         )\n",
    "with xr.open_dataset(s5p_files[1]) as sp5_img_GA:\n",
    "    print(colored(\"Global attributes: \\n\", \"green\"))\n",
    "    display(sp5_img_GA)\n",
    "    \n",
    "with xr.open_dataset(s5p_files[1], group = \"METADATA/GRANULE_DESCRIPTION\") as sp5_img_MT:\n",
    "    print(colored(\"METADATA/GRANULE_DESCRIPTION group: \\n\", \"green\"))\n",
    "    display(sp5_img_MT)\n",
    "    \n",
    "with xr.open_dataset(s5p_files[1], group=\"PRODUCT\").set_coords([\"latitude\", \"longitude\"]) as sp5_img_PRD:\n",
    "    print(colored(\"PRODUCT group: \\n\", \"green\"))\n",
    "    display(sp5_img_PRD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4294237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting SO2 variable\n",
    "so2 = sp5_img_PRD[\"sulfurdioxide_total_vertical_column\"]\n",
    "# Converting to DU\n",
    "so2 = so2*so2.multiplication_factor_to_convert_to_DU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f99f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "so2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6cc040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SO2 Product Visualization\n",
    "import warnings; warnings.filterwarnings(action='ignore')\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,12))\n",
    "ax = plt.axes(projection=ccrs.Orthographic(-90, 15))\n",
    "so2[0].plot.pcolormesh(ax=ax, x=\"longitude\", y=\"latitude\", add_colorbar=True,cmap=\"magma_r\",transform=ccrs.PlateCarree(),vmin=0)\n",
    "ax.set_title(\"Sentinel-5P L2 SO$_2$ (2021-02-28) | qa_value> 0\")\n",
    "ax.coastlines(\"10m\")\n",
    "ax.set_global()\n",
    "ax.stock_img()\n",
    "ax.gridlines()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3729f509",
   "metadata": {},
   "source": [
    "## 3. Filtering the low quality pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf5c07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "so2_filter = so2.where(sp5_img_PRD[\"qa_value\"] > 0.5, drop=True)\n",
    "# Plot original dagta vs quality flag\n",
    "plt.figure(figsize=(30, 10))\n",
    "\n",
    "# Plot qa_value image\n",
    "ax1 = plt.subplot(121, projection=ccrs.Orthographic(-90, 15))\n",
    "sp5_img_PRD[\"qa_value\"][0].plot.pcolormesh(ax=ax1, x=\"longitude\", y=\"latitude\",add_colorbar=True,cmap=\"Spectral\",transform=ccrs.PlateCarree())\n",
    "ax1.set_title(\"Sentinel-5P L2 SO$_2$ (2021-02-28) | Quality Flag Layer\")\n",
    "ax1.add_feature(cartopy.feature.LAND,edgecolor=\"black\")\n",
    "ax1.add_feature(cartopy.feature.OCEAN)\n",
    "ax1.coastlines(\"10m\")\n",
    "ax1.gridlines()\n",
    "ax1.set_global\n",
    "\n",
    "# Plot masked SO2 data\n",
    "ax2 = plt.subplot(122, projection=ccrs.Orthographic(-90, 15))\n",
    "so2_filter[0].plot.pcolormesh(ax=ax2, x=\"longitude\", y=\"latitude\",add_colorbar=True,cmap=\"magma_r\",transform=ccrs.PlateCarree(),vmin=0)\n",
    "ax2.set_title(\"Filtered Sentinel-5P L2 SO$_2$ (2021-02-28) | Quality Flag Layer > 0.75\")\n",
    "ax2.add_feature(cartopy.feature.LAND,edgecolor=\"black\")\n",
    "ax2.add_feature(cartopy.feature.OCEAN)\n",
    "ax2.coastlines(\"10m\")\n",
    "ax2.gridlines()\n",
    "ax2.set_global\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42239a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "so2_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6a6fc9",
   "metadata": {},
   "source": [
    "## 4. Subsetting to study area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43d46e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, DrawControl\n",
    "# Set the study area using ipyleaflet\n",
    "m = Map(center=(35.5, 14.5), zoom=6)\n",
    "draw_control = DrawControl(polyline={}, circlemarker={}, polygon={})\n",
    "draw_control.rectangle = {\n",
    "    \"shapeOptions\":{\n",
    "        \"fillColor\": \"#fca45d\",\n",
    "        \"Color\": \"#fca45d\",\n",
    "        \"fillOpacity\": 0.2\n",
    "    }\n",
    "    \n",
    "}\n",
    "m.add_control(draw_control)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efccef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrat ur and ll coordinates in LON, LAT order\n",
    "draw_control.last_draw['geometry']['coordinates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d49380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract UR and LL corner in LAT, LON order\n",
    "ll = draw_control.last_draw['geometry']['coordinates'][0][0][::-1]\n",
    "ur = draw_control.last_draw['geometry']['coordinates'][0][2][::-1]\n",
    "\n",
    "# Subset using xarray.where()\n",
    "so2_fltr_subset = so2_filter.where((so2_filter.longitude < ur[1]) & (so2_filter.longitude > ll[1]) & (so2_filter.latitude > ll[0]) & (so2_filter.latitude < ur[0]), drop=True) \n",
    "so2_subset = so2.where((so2.longitude < ur[1]) & (so2.longitude > ll[1]) & (so2.latitude > ll[0]) & (so2.latitude < ur[0]), drop=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccc4222",
   "metadata": {},
   "source": [
    " ## 5. Visualize SO2 subset product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aeff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original data vs filtered \n",
    "plt.figure(figsize=(30, 10))\n",
    "\n",
    "# Plot 1\n",
    "ax1 = plt.subplot(121, projection=ccrs.Orthographic(14.5, 35.5))\n",
    "so2_subset[0].plot.pcolormesh(ax=ax1, x='longitude', y='latitude', add_colorbar=True, cmap='magma_r', transform=ccrs.PlateCarree(), vmin=0) \n",
    "\n",
    "# Background\n",
    "ax1.add_feature(cartopy.feature.LAND, edgecolor='black')\n",
    "ax1.add_feature(cartopy.feature.BORDERS)\n",
    "ax1.add_feature(cartopy.feature.OCEAN)\n",
    "ax1.coastlines('10m')\n",
    "\n",
    "# Metadata\n",
    "ax1.plot(13.590427, 35.221091, '^:r', markersize=10, transform=ccrs.Geodetic())\n",
    "ax1.plot(15.11162, 36.476663, 'X:g', markersize=10, transform=ccrs.Geodetic())\n",
    "ax1.text(15.11162, 36.476663, 'Ciudad de Guatemala', transform=ccrs.Geodetic())\n",
    "ax1.set_title('S-5p L2 [SO$_2$] DU (2018-06-03)')\n",
    "gl = ax1.gridlines(draw_labels=True, linewidth=1, color='gray', linestyle='--')\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "\n",
    "# Plot 2\n",
    "ax2 = plt.subplot(122, projection=ccrs.Orthographic(14.5, 35.5))\n",
    "so2_fltr_subset[0].plot.pcolormesh(ax=ax2, x='longitude', y='latitude', add_colorbar=True, cmap='magma_r',transform=ccrs.PlateCarree(), vmin=0)\n",
    "\n",
    "# Background \n",
    "ax2.add_feature(cartopy.feature.LAND, edgecolor='black')\n",
    "ax2.add_feature(cartopy.feature.BORDERS)\n",
    "ax2.add_feature(cartopy.feature.OCEAN)\n",
    "ax2.coastlines('10m')\n",
    "\n",
    "# Metadata\n",
    "ax2.plot(13.590427, 35.221091, '^:r', markersize=10, transform=ccrs.Geodetic())\n",
    "ax2.plot(15.11162, 36.476663, 'X:g', markersize=10, transform=ccrs.Geodetic())\n",
    "ax2.text(15.11162, 36.476663, 'Ciudad de Guatemala', transform=ccrs.Geodetic());\n",
    "ax2.set_title('Filtered S-5p L2 [SO$_2$] DU (2018-06-03) | Quality Flag Layer > 0.5')\n",
    "gl2 = ax2.gridlines(draw_labels=True, linewidth=1, color='gray', linestyle='--')\n",
    "gl2.top_labels = False\n",
    "gl2.right_labels = False\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c08895f",
   "metadata": {},
   "source": [
    "## 2. Load and explore Sentinel-5P product (CO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac264e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_dir = \"C:/Users/mxr8032/Downloads/Bhushan_Pawar/S5P_CO/\"\n",
    "s5p_files = sorted([f for f in glob.glob(input_dir + \"*CO*.nc\", recursive = True)])\n",
    "#print(s5p_files)\n",
    "\n",
    "for i, file in enumerate(s5p_files):\n",
    "    s5p_split = file.split(\"/\")\n",
    "    s5p_split_file = s5p_split[-1].split(\"_\")\n",
    "    print(\"#{}: {} \\n\".format(i,s5p_split[-1]),\n",
    "         colored(\"Mission:\", \"blue\"),\"{}\".format(s5p_split_file[0]),\n",
    "         colored(\"Stream | Level:\", \"blue\"), \"{} | {}\".format(s5p_split_file[1], s5p_split_file[2]),\n",
    "         colored(\"Product identifier:\", \"blue\"), \"{}\".format(s5p_split_file[4]),\n",
    "         colored(\"Start | End:\", \"blue\"), \"{} | {}\".format(s5p_split_file[8],s5p_split_file[9]),\n",
    "         colored(\"Orbit:\", \"blue\"), \"{}\".format(s5p_split_file[10]),\n",
    "         colored(\"Collect.:\", \"blue\"), \"{}\".format(s5p_split_file[11]),\n",
    "         colored(\"Processor:\", \"blue\"), \"{}\".format(s5p_split_file[12]),\n",
    "         colored(\"Process time:\", \"blue\"), \"{}\".format(s5p_split_file[1]), \"\\n\"\n",
    "         )\n",
    "with xr.open_dataset(s5p_files[1]) as sp5_img_GA:\n",
    "    print(colored(\"Global attributes: \\n\", \"green\"))\n",
    "    display(sp5_img_GA)\n",
    "    \n",
    "with xr.open_dataset(s5p_files[1], group = \"METADATA/GRANULE_DESCRIPTION\") as sp5_img_MT:\n",
    "    print(colored(\"METADATA/GRANULE_DESCRIPTION group: \\n\", \"green\"))\n",
    "    display(sp5_img_MT)\n",
    "    \n",
    "with xr.open_dataset(s5p_files[1], group=\"PRODUCT\").set_coords([\"latitude\", \"longitude\"]) as sp5_img_PRD:\n",
    "    print(colored(\"PRODUCT group: \\n\", \"green\"))\n",
    "    display(sp5_img_PRD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29105f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting SO2 variable\n",
    "co = sp5_img_PRD[\"carbonmonoxide_total_column\"]\n",
    "co\n",
    "# Converting to DU\n",
    "#so2 = so2*so2.multiplication_factor_to_convert_to_DU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c986d99a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CO Product Visualization\n",
    "import warnings; warnings.filterwarnings(action='ignore')\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,12))\n",
    "ax = plt.axes(projection=ccrs.Orthographic(14.5, 35.5))\n",
    "co[0].plot.pcolormesh(ax=ax, x=\"longitude\", y=\"latitude\", add_colorbar=True,cmap=\"magma_r\",transform=ccrs.PlateCarree(),vmin=0)\n",
    "ax.set_title(\"Sentinel-5P L2 CO$_2$ (2021-01-01) | qa_value> 0\")\n",
    "ax.coastlines(\"10m\")\n",
    "ax.set_global()\n",
    "ax.stock_img()\n",
    "ax.gridlines()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccbd90e",
   "metadata": {},
   "source": [
    "## Load and explore Sentinel-5P product (CO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182393b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"C:/Users/mxr8032/Downloads/Bhushan_Pawar/S5P_CLOUD/\"\n",
    "s5p_files = sorted([f for f in glob.glob(input_dir + \"*CLOUD*.nc\", recursive = True)])\n",
    "#print(s5p_files)\n",
    "\n",
    "for i, file in enumerate(s5p_files):\n",
    "    s5p_split = file.split(\"/\")\n",
    "    s5p_split_file = s5p_split[-1].split(\"_\")\n",
    "    print(\"#{}: {} \\n\".format(i,s5p_split[-1]),\n",
    "         colored(\"Mission:\", \"blue\"),\"{}\".format(s5p_split_file[0]),\n",
    "         colored(\"Stream | Level:\", \"blue\"), \"{} | {}\".format(s5p_split_file[1], s5p_split_file[2]),\n",
    "         colored(\"Product identifier:\", \"blue\"), \"{}\".format(s5p_split_file[4]),\n",
    "         colored(\"Start | End:\", \"blue\"), \"{} | {}\".format(s5p_split_file[8],s5p_split_file[9]),\n",
    "         colored(\"Orbit:\", \"blue\"), \"{}\".format(s5p_split_file[10]),\n",
    "         colored(\"Collect.:\", \"blue\"), \"{}\".format(s5p_split_file[11]),\n",
    "         colored(\"Processor:\", \"blue\"), \"{}\".format(s5p_split_file[12]),\n",
    "         colored(\"Process time:\", \"blue\"), \"{}\".format(s5p_split_file[1]), \"\\n\"\n",
    "         )\n",
    "with xr.open_dataset(s5p_files[1]) as sp5_img_GA:\n",
    "    print(colored(\"Global attributes: \\n\", \"green\"))\n",
    "    display(sp5_img_GA)\n",
    "    \n",
    "with xr.open_dataset(s5p_files[1], group = \"METADATA/GRANULE_DESCRIPTION\") as sp5_img_MT:\n",
    "    print(colored(\"METADATA/GRANULE_DESCRIPTION group: \\n\", \"green\"))\n",
    "    display(sp5_img_MT)\n",
    "    \n",
    "with xr.open_dataset(s5p_files[1], group=\"PRODUCT\").set_coords([\"latitude\", \"longitude\"]) as sp5_img_PRD:\n",
    "    print(colored(\"PRODUCT group: \\n\", \"green\"))\n",
    "    display(sp5_img_PRD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf382681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting SO2 variable\n",
    "cloud = sp5_img_PRD[\"cloud_optical_thickness\"]\n",
    "cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e76f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLOUD Product Visualization\n",
    "import warnings; warnings.filterwarnings(action='ignore')\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,12))\n",
    "ax = plt.axes(projection=ccrs.Orthographic(14.5, 35.5))\n",
    "cloud[0].plot.pcolormesh(ax=ax, x=\"longitude\", y=\"latitude\", add_colorbar=True,cmap=\"magma_r\",transform=ccrs.PlateCarree(),vmin=0)\n",
    "ax.set_title(\"Sentinel-5P L2 CLOUD$_2$ (2021-01-01) | qa_value> 0\")\n",
    "ax.coastlines(\"10m\")\n",
    "ax.set_global()\n",
    "ax.stock_img()\n",
    "ax.gridlines()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868a31ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
